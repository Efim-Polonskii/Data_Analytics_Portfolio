{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac77ea-85eb-4328-a6ed-de9ddd0eb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "#print(f\"Текущая рабочая директория Jupyter: {current_working_directory}\")\n",
    "\n",
    "# Путь к папке Project_GameDataAnalysis\n",
    "# ноутбук находится в Project_GameDataAnalysis/notebooks/\n",
    "# Если Jupyter запущен из Project_GameDataAnalysis:\n",
    "if os.path.basename(current_working_directory) == 'Project_GameDataAnalysis':\n",
    "    project_root_path = current_working_directory\n",
    "elif os.path.basename(current_working_directory) == 'notebooks' and \\\n",
    "     os.path.basename(os.path.dirname(current_working_directory)) == 'Project_GameDataAnalysis':\n",
    "    project_root_path = os.path.dirname(current_working_directory)\n",
    "# Если Jupyter запущен из Data_Analytics_Portfolio:\n",
    "elif os.path.basename(current_working_directory) == 'Data_Analytics_Portfolio':\n",
    "    project_root_path = os.path.join(current_working_directory, 'Project_GameDataAnalysis')\n",
    "else:\n",
    "    # Запасной вариант \n",
    "    print(\"Убедитесь, что Jupyter запущен из Data_Analytics_Portfolio или Project_GameDataAnalysis.\")\n",
    "    project_root_path = None # Устанавливаем None, чтобы предотвратить дальнейшие ошибки\n",
    "\n",
    "if project_root_path:\n",
    "    # Добавляем корневую папку Project_GameDataAnalysis в sys.path для импорта load_data.py\n",
    "    if project_root_path not in sys.path:\n",
    "        sys.path.append(project_root_path)\n",
    "        print(f\"'{project_root_path}' добавлен в sys.path.\")\n",
    "    else:\n",
    "        #print(f\"'{project_root_path}' уже в sys.path.\")\n",
    "        print(f\" уже в sys.path.\")\n",
    "\n",
    "    # Импортируем нашу функцию для загрузки данных из скрипта load_data.py\n",
    "    # load_data.py находится непосредственно в Project_GameDataAnalysis\n",
    "    from load_data import load_game_data\n",
    "\n",
    "    # Загружаем данные, передавая project_root_path как base_path\n",
    "    # Теперь load_data.py будет искать папку 'data' относительно project_root_path\n",
    "    df = load_game_data(base_path=project_root_path)\n",
    "\n",
    "    # Проверяем, что данные загрузились\n",
    "    if df is not None:\n",
    "        print(\"\\nДанные успешно загружены в ноутбук!\")\n",
    "        print(\"\\nПервые 5 строк данных:\")\n",
    "        from IPython.display import display # Убедимся, что display импортирован\n",
    "        display(df.head())\n",
    "        print(\"\\nИнформация о столбцах:\")\n",
    "        df.info()\n",
    "    else:\n",
    "        print(\"Не удалось загрузить данные. Проверьте пути.\")\n",
    "else:\n",
    "    print(\"Не удалось определить корневую директорию проекта. Данные не загружены.\")\n",
    "    df = None # Устанавливаем df в None, чтобы избежать ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b5527-9993-463e-8a0d-3e4f9d818a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим количество уникальных значений в столбцах типа 'object'\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    print(f\"Столбец '{col}': {df[col].nunique()} уникальных значений\")\n",
    "    if df[col].nunique() < 50: # Смотрим, если меньше 50\n",
    "        print(df[col].value_counts(dropna=False)) # dropna=False смотрим и NaN\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Посмотрим на статистические сводки для числовых столбцов\n",
    "print(\"\\nСтатистические сводки для числовых столбцов:\")\n",
    "print(df.describe())\n",
    "\n",
    "# --- Вставляем сюда проверку после обработки Name и Genre ---\n",
    "# Количество пропущенных значений по столбцам ДО обработки Name и Genre\n",
    "print(\"\\nКоличество пропущенных значений ДО обработки Name и Genre:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Удаляем строки, где Name или Genre являются NaN\n",
    "rows_before_name_genre_dropna = len(df)\n",
    "df.dropna(subset=['Name', 'Genre'], inplace=True)\n",
    "rows_after_name_genre_dropna = len(df)\n",
    "print(f\"\\nУдалено {rows_before_name_genre_dropna - rows_after_name_genre_dropna} строк из-за NaN в 'Name' или 'Genre'.\")\n",
    "\n",
    "# Проверяем состояние DataFrame после удаления строк по Name и Genre\n",
    "print(\"\\nСостояние DataFrame после удаления строк с NaN в Name/Genre:\")\n",
    "print(df.info())\n",
    "print(\"\\nРазмер DataFrame после удаления по Name/Genre:\", df.shape)\n",
    "\n",
    "# --- Добавим специфическую диагностику для Year_of_Release здесь ---\n",
    "# Теперь, когда Name и Genre обработаны, давайте посмотрим на Year_of_Release\n",
    "print(\"\\n*** Диагностика Year_of_Release ***\")\n",
    "print(\"Уникальные значения в 'Year_of_Release' до преобразования:\")\n",
    "# Увеличим head() на всякий случай, если есть много разных строковых представлений дат\n",
    "print(df['Year_of_Release'].value_counts(dropna=False).head(50))\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e71f9-8954-439a-9717-4223e8ebc354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Обработка User_Score ---\n",
    "print(\"Обработка столбца 'User_Score'...\")\n",
    "# Заменяем 'tbd' в User_Score на NaN\n",
    "initial_tbd_count = (df['User_Score'] == 'tbd').sum()\n",
    "df['User_Score'] = df['User_Score'].replace('tbd', np.nan)\n",
    "print(f\"Заменено '{initial_tbd_count}' значений 'tbd' на NaN в 'User_Score'.\")\n",
    "\n",
    "# Преобразуем User_Score в числовой тип (float)\n",
    "# errors='coerce' здесь важен, если есть другие нечисловые значения\n",
    "df['User_Score'] = pd.to_numeric(df['User_Score'], errors='coerce')\n",
    "\n",
    "# --- Обработка Year_of_Release ---\n",
    "print(\"\\nОбработка столбца 'Year_of_Release'...\")\n",
    "\n",
    "# Преобразуем столбец 'Year_of_Release' в datetime формат\n",
    "# errors='coerce' заменит некорректные даты на NaT (Not a Time)\n",
    "df['Year_of_Release'] = pd.to_datetime(df['Year_of_Release'], errors='coerce')\n",
    "\n",
    "# Извлекаем год из столбца datetime\n",
    "# .dt.year позволяет получить год\n",
    "df['Year_of_Release'] = df['Year_of_Release'].dt.year\n",
    "\n",
    "# Удаляем строки, где 'Year_of_Release' стало NaN после преобразования (некорректные или пустые даты)\n",
    "rows_before_year_dropna = len(df)\n",
    "df.dropna(subset=['Year_of_Release'], inplace=True)\n",
    "rows_after_year_dropna = len(df)\n",
    "print(f\"Удалено {rows_before_year_dropna - rows_after_year_dropna} строк из-за NaN в 'Year_of_Release' (после обработки даты).\")\n",
    "\n",
    "# Преобразуем в целочисленный тип \n",
    "df['Year_of_Release'] = df['Year_of_Release'].astype(int)\n",
    "\n",
    "# --- Проверка результата ---\n",
    "print(\"\\nСостояние DataFrame после обработки User_Score и Year_of_Release:\")\n",
    "print(df.info())\n",
    "print(\"\\nРазмер DataFrame:\", df.shape)\n",
    "print(\"\\nПервые 5 строк с обновленными 'User_Score' и 'Year_of_Release':\")\n",
    "from IPython.display import display\n",
    "display(df[['Name', 'User_Score', 'Year_of_Release']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395784a-eea4-4374-a7b8-7b294a6475f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Project Data Analysis)",
   "language": "python",
   "name": "data_analysis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
